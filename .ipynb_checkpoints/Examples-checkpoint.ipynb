{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a53e823",
   "metadata": {},
   "outputs": [],
   "source": [
    "from investment_predictions import DataScraper, DataParser\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import time\n",
    "import openpyxl\n",
    "\n",
    "\n",
    "key_path = Path().home()/'desktop'/'FinancialModellingPrep_API.txt'\n",
    "with open(key_path) as file:\n",
    "    api_key = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf78b9cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "a = DataScraper('S&P500', api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989a4176",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.data_dictionary['price'][0].to_parquet('snp500_trading_data_1970_to_2023.parquet', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35dea88f",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0x90 in position 7: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m b \u001b[38;5;241m=\u001b[39m \u001b[43mDataParser\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_dictionary\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\Git\\investment-predictions\\investment_predictions\\data_parser.py:36\u001b[0m, in \u001b[0;36mDataParser.__init__\u001b[1;34m(self, data_dictionary)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_income_statement()\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprice \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilter_daily_into_quarters(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_price())\n\u001b[1;32m---> 36\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msnp_500 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilter_daily_into_quarters(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_snp_500\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilter_dataframes()\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcalculate_PE_ratios()\n",
      "File \u001b[1;32m~\\Desktop\\Git\\investment-predictions\\investment_predictions\\data_parser.py:116\u001b[0m, in \u001b[0;36mDataParser.load_snp_500\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_snp_500\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    113\u001b[0m     path \u001b[38;5;241m=\u001b[39m Path\u001b[38;5;241m.\u001b[39mcwd()\u001b[38;5;241m/\u001b[39m\\\n\u001b[0;32m    114\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minvestment_predictions\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m/\u001b[39m\\\n\u001b[0;32m    115\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msnp500_trading_data_1970_to_2023.parquet\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 116\u001b[0m     df \u001b[38;5;241m=\u001b[39m  \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    117\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_date_objects_from_pd_timestamps(df\u001b[38;5;241m.\u001b[39mindex)\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\investment_predictions\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\investment_predictions\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\investment_predictions\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\investment_predictions\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\investment_predictions\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\investment_predictions\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1753\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1750\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m   1752\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1753\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mapping[engine](f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions)\n\u001b[0;32m   1754\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1755\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\investment_predictions\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:79\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     76\u001b[0m     kwds\u001b[38;5;241m.\u001b[39mpop(key, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     78\u001b[0m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m ensure_dtype_objs(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m---> 79\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader \u001b[38;5;241m=\u001b[39m parsers\u001b[38;5;241m.\u001b[39mTextReader(src, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munnamed_cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39munnamed_cols\n\u001b[0;32m     83\u001b[0m \u001b[38;5;66;03m# error: Cannot determine type of 'names'\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\investment_predictions\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:547\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\investment_predictions\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:664\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._get_header\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0x90 in position 7: invalid start byte"
     ]
    }
   ],
   "source": [
    "b = DataParser(a.data_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad2fc491",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'date'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilter_daily_into_quarters\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msnp_500\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\Git\\investment-predictions\\investment_predictions\\data_parser.py:127\u001b[0m, in \u001b[0;36mDataParser.filter_daily_into_quarters\u001b[1;34m(self, df)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m start, end, idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(start_date_objects, end_date_objects, working_index):\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 127\u001b[0m         period_price \u001b[38;5;241m=\u001b[39m df[(\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdate\u001b[49m\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39mstart) \u001b[38;5;241m&\u001b[39m (df\u001b[38;5;241m.\u001b[39mdate\u001b[38;5;241m<\u001b[39mend)]\n\u001b[0;32m    128\u001b[0m         max_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(period_price[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHigh\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m    129\u001b[0m         min_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(period_price[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLow\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\investment_predictions\\lib\\site-packages\\pandas\\core\\generic.py:5902\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5895\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   5896\u001b[0m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set\n\u001b[0;32m   5897\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[0;32m   5898\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessors\n\u001b[0;32m   5899\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[0;32m   5900\u001b[0m ):\n\u001b[0;32m   5901\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[1;32m-> 5902\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'date'"
     ]
    }
   ],
   "source": [
    "b.filter_daily_into_quarters(b.snp_500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cdab5af5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AAPL-Q1-2022    1.890000\n",
       "AAPL-Q4-2022    1.290000\n",
       "AAPL-Q3-2022    1.200000\n",
       "AAPL-Q2-2022    1.540000\n",
       "AAPL-Q1-2021    2.110000\n",
       "                  ...   \n",
       "AAPL-Q4-1986    0.000000\n",
       "AAPL-Q3-1986    0.002321\n",
       "AAPL-Q2-1986    0.002321\n",
       "AAPL-Q1-1985    0.004107\n",
       "AAPL-Q4-1985    0.000000\n",
       "Name: eps, Length: 150, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.is_.eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "768d72f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.is_.index.equals(b.ratios.index.equals(b.metrics.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "084028a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "diffs = []\n",
    "import datetime as dt\n",
    "for i, item in enumerate(b.metrics.date[1:]):\n",
    "    ly, lm, ld = [int(x) for x in b.ratios.date[i].split('-')]\n",
    "    last_date = dt.datetime(ly, lm, ld)\n",
    "    y, m, d = [int(x) for x in item.split('-')]\n",
    "    date_now = dt.datetime(y, m, d)\n",
    "    diffs.append(date_now-last_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9124f71d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-90),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-90),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-90),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-90),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-90),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-90),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-90),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-90),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-90),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-90),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-90),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-90),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-90),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-90),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-90),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-90),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-90),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-90),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-90),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-90),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-90),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-90),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-90),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-90),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-90),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-90),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-90),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-90),\n",
       " datetime.timedelta(days=-92)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22272446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function intersection in module pandas.core.indexes.base:\n",
      "\n",
      "intersection(self, other, sort=False)\n",
      "    Form the intersection of two Index objects.\n",
      "    \n",
      "    This returns a new Index with elements common to the index and `other`.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    other : Index or array-like\n",
      "    sort : False or None, default False\n",
      "        Whether to sort the resulting index.\n",
      "    \n",
      "        * False : do not sort the result.\n",
      "        * None : sort the result, except when `self` and `other` are equal\n",
      "          or when the values cannot be compared.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    intersection : Index\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> idx1 = pd.Index([1, 2, 3, 4])\n",
      "    >>> idx2 = pd.Index([3, 4, 5, 6])\n",
      "    >>> idx1.intersection(idx2)\n",
      "    Int64Index([3, 4], dtype='int64')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pd.Index.intersection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "496957cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas._libs.tslibs.timestamps.Timestamp"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(b.data_dictionary['price'][0].index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28e39a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas._libs.tslibs.timestamps import Timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "116e1dd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2020-10-01 00:00:00')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Timestamp(\"2020-10-01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ecb36f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function concat in module pandas.core.reshape.concat:\n",
      "\n",
      "concat(objs: 'Iterable[NDFrame] | Mapping[HashableT, NDFrame]', *, axis: 'Axis' = 0, join: 'str' = 'outer', ignore_index: 'bool' = False, keys=None, levels=None, names=None, verify_integrity: 'bool' = False, sort: 'bool' = False, copy: 'bool' = True) -> 'DataFrame | Series'\n",
      "    Concatenate pandas objects along a particular axis.\n",
      "    \n",
      "    Allows optional set logic along the other axes.\n",
      "    \n",
      "    Can also add a layer of hierarchical indexing on the concatenation axis,\n",
      "    which may be useful if the labels are the same (or overlapping) on\n",
      "    the passed axis number.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    objs : a sequence or mapping of Series or DataFrame objects\n",
      "        If a mapping is passed, the sorted keys will be used as the `keys`\n",
      "        argument, unless it is passed, in which case the values will be\n",
      "        selected (see below). Any None objects will be dropped silently unless\n",
      "        they are all None in which case a ValueError will be raised.\n",
      "    axis : {0/'index', 1/'columns'}, default 0\n",
      "        The axis to concatenate along.\n",
      "    join : {'inner', 'outer'}, default 'outer'\n",
      "        How to handle indexes on other axis (or axes).\n",
      "    ignore_index : bool, default False\n",
      "        If True, do not use the index values along the concatenation axis. The\n",
      "        resulting axis will be labeled 0, ..., n - 1. This is useful if you are\n",
      "        concatenating objects where the concatenation axis does not have\n",
      "        meaningful indexing information. Note the index values on the other\n",
      "        axes are still respected in the join.\n",
      "    keys : sequence, default None\n",
      "        If multiple levels passed, should contain tuples. Construct\n",
      "        hierarchical index using the passed keys as the outermost level.\n",
      "    levels : list of sequences, default None\n",
      "        Specific levels (unique values) to use for constructing a\n",
      "        MultiIndex. Otherwise they will be inferred from the keys.\n",
      "    names : list, default None\n",
      "        Names for the levels in the resulting hierarchical index.\n",
      "    verify_integrity : bool, default False\n",
      "        Check whether the new concatenated axis contains duplicates. This can\n",
      "        be very expensive relative to the actual data concatenation.\n",
      "    sort : bool, default False\n",
      "        Sort non-concatenation axis if it is not already aligned when `join`\n",
      "        is 'outer'.\n",
      "        This has no effect when ``join='inner'``, which already preserves\n",
      "        the order of the non-concatenation axis.\n",
      "    \n",
      "        .. versionchanged:: 1.0.0\n",
      "    \n",
      "           Changed to not sort by default.\n",
      "    \n",
      "    copy : bool, default True\n",
      "        If False, do not copy data unnecessarily.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    object, type of objs\n",
      "        When concatenating all ``Series`` along the index (axis=0), a\n",
      "        ``Series`` is returned. When ``objs`` contains at least one\n",
      "        ``DataFrame``, a ``DataFrame`` is returned. When concatenating along\n",
      "        the columns (axis=1), a ``DataFrame`` is returned.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    DataFrame.join : Join DataFrames using indexes.\n",
      "    DataFrame.merge : Merge DataFrames by indexes or columns.\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    The keys, levels, and names arguments are all optional.\n",
      "    \n",
      "    A walkthrough of how this method fits in with other tools for combining\n",
      "    pandas objects can be found `here\n",
      "    <https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html>`__.\n",
      "    \n",
      "    It is not recommended to build DataFrames by adding single rows in a\n",
      "    for loop. Build a list of rows and make a DataFrame in a single concat.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    Combine two ``Series``.\n",
      "    \n",
      "    >>> s1 = pd.Series(['a', 'b'])\n",
      "    >>> s2 = pd.Series(['c', 'd'])\n",
      "    >>> pd.concat([s1, s2])\n",
      "    0    a\n",
      "    1    b\n",
      "    0    c\n",
      "    1    d\n",
      "    dtype: object\n",
      "    \n",
      "    Clear the existing index and reset it in the result\n",
      "    by setting the ``ignore_index`` option to ``True``.\n",
      "    \n",
      "    >>> pd.concat([s1, s2], ignore_index=True)\n",
      "    0    a\n",
      "    1    b\n",
      "    2    c\n",
      "    3    d\n",
      "    dtype: object\n",
      "    \n",
      "    Add a hierarchical index at the outermost level of\n",
      "    the data with the ``keys`` option.\n",
      "    \n",
      "    >>> pd.concat([s1, s2], keys=['s1', 's2'])\n",
      "    s1  0    a\n",
      "        1    b\n",
      "    s2  0    c\n",
      "        1    d\n",
      "    dtype: object\n",
      "    \n",
      "    Label the index keys you create with the ``names`` option.\n",
      "    \n",
      "    >>> pd.concat([s1, s2], keys=['s1', 's2'],\n",
      "    ...           names=['Series name', 'Row ID'])\n",
      "    Series name  Row ID\n",
      "    s1           0         a\n",
      "                 1         b\n",
      "    s2           0         c\n",
      "                 1         d\n",
      "    dtype: object\n",
      "    \n",
      "    Combine two ``DataFrame`` objects with identical columns.\n",
      "    \n",
      "    >>> df1 = pd.DataFrame([['a', 1], ['b', 2]],\n",
      "    ...                    columns=['letter', 'number'])\n",
      "    >>> df1\n",
      "      letter  number\n",
      "    0      a       1\n",
      "    1      b       2\n",
      "    >>> df2 = pd.DataFrame([['c', 3], ['d', 4]],\n",
      "    ...                    columns=['letter', 'number'])\n",
      "    >>> df2\n",
      "      letter  number\n",
      "    0      c       3\n",
      "    1      d       4\n",
      "    >>> pd.concat([df1, df2])\n",
      "      letter  number\n",
      "    0      a       1\n",
      "    1      b       2\n",
      "    0      c       3\n",
      "    1      d       4\n",
      "    \n",
      "    Combine ``DataFrame`` objects with overlapping columns\n",
      "    and return everything. Columns outside the intersection will\n",
      "    be filled with ``NaN`` values.\n",
      "    \n",
      "    >>> df3 = pd.DataFrame([['c', 3, 'cat'], ['d', 4, 'dog']],\n",
      "    ...                    columns=['letter', 'number', 'animal'])\n",
      "    >>> df3\n",
      "      letter  number animal\n",
      "    0      c       3    cat\n",
      "    1      d       4    dog\n",
      "    >>> pd.concat([df1, df3], sort=False)\n",
      "      letter  number animal\n",
      "    0      a       1    NaN\n",
      "    1      b       2    NaN\n",
      "    0      c       3    cat\n",
      "    1      d       4    dog\n",
      "    \n",
      "    Combine ``DataFrame`` objects with overlapping columns\n",
      "    and return only those that are shared by passing ``inner`` to\n",
      "    the ``join`` keyword argument.\n",
      "    \n",
      "    >>> pd.concat([df1, df3], join=\"inner\")\n",
      "      letter  number\n",
      "    0      a       1\n",
      "    1      b       2\n",
      "    0      c       3\n",
      "    1      d       4\n",
      "    \n",
      "    Combine ``DataFrame`` objects horizontally along the x axis by\n",
      "    passing in ``axis=1``.\n",
      "    \n",
      "    >>> df4 = pd.DataFrame([['bird', 'polly'], ['monkey', 'george']],\n",
      "    ...                    columns=['animal', 'name'])\n",
      "    >>> pd.concat([df1, df4], axis=1)\n",
      "      letter  number  animal    name\n",
      "    0      a       1    bird   polly\n",
      "    1      b       2  monkey  george\n",
      "    \n",
      "    Prevent the result from including duplicate index values with the\n",
      "    ``verify_integrity`` option.\n",
      "    \n",
      "    >>> df5 = pd.DataFrame([1], index=['a'])\n",
      "    >>> df5\n",
      "       0\n",
      "    a  1\n",
      "    >>> df6 = pd.DataFrame([2], index=['a'])\n",
      "    >>> df6\n",
      "       0\n",
      "    a  2\n",
      "    >>> pd.concat([df5, df6], verify_integrity=True)\n",
      "    Traceback (most recent call last):\n",
      "        ...\n",
      "    ValueError: Indexes have overlapping values: ['a']\n",
      "    \n",
      "    Append a single row to the end of a ``DataFrame`` object.\n",
      "    \n",
      "    >>> df7 = pd.DataFrame({'a': 1, 'b': 2}, index=[0])\n",
      "    >>> df7\n",
      "        a   b\n",
      "    0   1   2\n",
      "    >>> new_row = pd.Series({'a': 3, 'b': 4})\n",
      "    >>> new_row\n",
      "    a    3\n",
      "    b    4\n",
      "    dtype: int64\n",
      "    >>> pd.concat([df7, new_row.to_frame().T], ignore_index=True)\n",
      "        a   b\n",
      "    0   1   2\n",
      "    1   3   4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pd.concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21df756a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
