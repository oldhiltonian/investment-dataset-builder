{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a53e823",
   "metadata": {},
   "outputs": [],
   "source": [
    "from investment_predictions import DataScraper, DataParser\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import time\n",
    "import openpyxl\n",
    "\n",
    "\n",
    "key_path = Path().home()/'desktop'/'FinancialModellingPrep_API.txt'\n",
    "with open(key_path) as file:\n",
    "    api_key = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf78b9cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "a = DataScraper('AAPL', api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35dea88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = DataParser(a.data_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad2fc491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S&amp;P500PriceAverage</th>\n",
       "      <th>S&amp;P500PriceHigh</th>\n",
       "      <th>S&amp;P500PriceLow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AAPL-Q1-2022</th>\n",
       "      <td>3851.973501</td>\n",
       "      <td>4100.959961</td>\n",
       "      <td>3491.580078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAPL-Q4-2022</th>\n",
       "      <td>3997.156843</td>\n",
       "      <td>4325.279785</td>\n",
       "      <td>3647.469971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAPL-Q3-2022</th>\n",
       "      <td>4154.281786</td>\n",
       "      <td>4637.299805</td>\n",
       "      <td>3636.870117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAPL-Q2-2022</th>\n",
       "      <td>4481.501101</td>\n",
       "      <td>4818.620117</td>\n",
       "      <td>4114.649902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAPL-Q1-2021</th>\n",
       "      <td>4572.733313</td>\n",
       "      <td>4743.830078</td>\n",
       "      <td>4278.939941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAPL-Q4-1986</th>\n",
       "      <td>241.290634</td>\n",
       "      <td>254.240005</td>\n",
       "      <td>228.080002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAPL-Q3-1986</th>\n",
       "      <td>240.346875</td>\n",
       "      <td>250.130005</td>\n",
       "      <td>226.300003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAPL-Q2-1986</th>\n",
       "      <td>218.996935</td>\n",
       "      <td>240.110001</td>\n",
       "      <td>202.600006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAPL-Q1-1985</th>\n",
       "      <td>196.383968</td>\n",
       "      <td>213.080002</td>\n",
       "      <td>181.160004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAPL-Q4-1985</th>\n",
       "      <td>188.654032</td>\n",
       "      <td>196.070007</td>\n",
       "      <td>179.449997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              S&P500PriceAverage  S&P500PriceHigh  S&P500PriceLow\n",
       "AAPL-Q1-2022         3851.973501      4100.959961     3491.580078\n",
       "AAPL-Q4-2022         3997.156843      4325.279785     3647.469971\n",
       "AAPL-Q3-2022         4154.281786      4637.299805     3636.870117\n",
       "AAPL-Q2-2022         4481.501101      4818.620117     4114.649902\n",
       "AAPL-Q1-2021         4572.733313      4743.830078     4278.939941\n",
       "...                          ...              ...             ...\n",
       "AAPL-Q4-1986          241.290634       254.240005      228.080002\n",
       "AAPL-Q3-1986          240.346875       250.130005      226.300003\n",
       "AAPL-Q2-1986          218.996935       240.110001      202.600006\n",
       "AAPL-Q1-1985          196.383968       213.080002      181.160004\n",
       "AAPL-Q4-1985          188.654032       196.070007      179.449997\n",
       "\n",
       "[150 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.snp_500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cdab5af5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AAPL-Q1-2022    1.890000\n",
       "AAPL-Q4-2022    1.290000\n",
       "AAPL-Q3-2022    1.200000\n",
       "AAPL-Q2-2022    1.540000\n",
       "AAPL-Q1-2021    2.110000\n",
       "                  ...   \n",
       "AAPL-Q4-1986    0.000000\n",
       "AAPL-Q3-1986    0.002321\n",
       "AAPL-Q2-1986    0.002321\n",
       "AAPL-Q1-1985    0.004107\n",
       "AAPL-Q4-1985    0.000000\n",
       "Name: eps, Length: 150, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.is_.eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "768d72f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.is_.index.equals(b.ratios.index.equals(b.metrics.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "084028a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "diffs = []\n",
    "import datetime as dt\n",
    "for i, item in enumerate(b.metrics.date[1:]):\n",
    "    ly, lm, ld = [int(x) for x in b.ratios.date[i].split('-')]\n",
    "    last_date = dt.datetime(ly, lm, ld)\n",
    "    y, m, d = [int(x) for x in item.split('-')]\n",
    "    date_now = dt.datetime(y, m, d)\n",
    "    diffs.append(date_now-last_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9124f71d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-90),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-90),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-90),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-90),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-90),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-90),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-90),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-90),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-90),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-90),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-90),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-90),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-90),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-90),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-90),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-90),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-90),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-90),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-90),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-90),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-90),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-90),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-90),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-90),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-90),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-90),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-90),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-90),\n",
       " datetime.timedelta(days=-92)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22272446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function intersection in module pandas.core.indexes.base:\n",
      "\n",
      "intersection(self, other, sort=False)\n",
      "    Form the intersection of two Index objects.\n",
      "    \n",
      "    This returns a new Index with elements common to the index and `other`.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    other : Index or array-like\n",
      "    sort : False or None, default False\n",
      "        Whether to sort the resulting index.\n",
      "    \n",
      "        * False : do not sort the result.\n",
      "        * None : sort the result, except when `self` and `other` are equal\n",
      "          or when the values cannot be compared.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    intersection : Index\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> idx1 = pd.Index([1, 2, 3, 4])\n",
      "    >>> idx2 = pd.Index([3, 4, 5, 6])\n",
      "    >>> idx1.intersection(idx2)\n",
      "    Int64Index([3, 4], dtype='int64')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pd.Index.intersection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "496957cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas._libs.tslibs.timestamps.Timestamp"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(b.data_dictionary['price'][0].index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28e39a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas._libs.tslibs.timestamps import Timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "116e1dd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2020-10-01 00:00:00')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Timestamp(\"2020-10-01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ecb36f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function concat in module pandas.core.reshape.concat:\n",
      "\n",
      "concat(objs: 'Iterable[NDFrame] | Mapping[HashableT, NDFrame]', *, axis: 'Axis' = 0, join: 'str' = 'outer', ignore_index: 'bool' = False, keys=None, levels=None, names=None, verify_integrity: 'bool' = False, sort: 'bool' = False, copy: 'bool' = True) -> 'DataFrame | Series'\n",
      "    Concatenate pandas objects along a particular axis.\n",
      "    \n",
      "    Allows optional set logic along the other axes.\n",
      "    \n",
      "    Can also add a layer of hierarchical indexing on the concatenation axis,\n",
      "    which may be useful if the labels are the same (or overlapping) on\n",
      "    the passed axis number.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    objs : a sequence or mapping of Series or DataFrame objects\n",
      "        If a mapping is passed, the sorted keys will be used as the `keys`\n",
      "        argument, unless it is passed, in which case the values will be\n",
      "        selected (see below). Any None objects will be dropped silently unless\n",
      "        they are all None in which case a ValueError will be raised.\n",
      "    axis : {0/'index', 1/'columns'}, default 0\n",
      "        The axis to concatenate along.\n",
      "    join : {'inner', 'outer'}, default 'outer'\n",
      "        How to handle indexes on other axis (or axes).\n",
      "    ignore_index : bool, default False\n",
      "        If True, do not use the index values along the concatenation axis. The\n",
      "        resulting axis will be labeled 0, ..., n - 1. This is useful if you are\n",
      "        concatenating objects where the concatenation axis does not have\n",
      "        meaningful indexing information. Note the index values on the other\n",
      "        axes are still respected in the join.\n",
      "    keys : sequence, default None\n",
      "        If multiple levels passed, should contain tuples. Construct\n",
      "        hierarchical index using the passed keys as the outermost level.\n",
      "    levels : list of sequences, default None\n",
      "        Specific levels (unique values) to use for constructing a\n",
      "        MultiIndex. Otherwise they will be inferred from the keys.\n",
      "    names : list, default None\n",
      "        Names for the levels in the resulting hierarchical index.\n",
      "    verify_integrity : bool, default False\n",
      "        Check whether the new concatenated axis contains duplicates. This can\n",
      "        be very expensive relative to the actual data concatenation.\n",
      "    sort : bool, default False\n",
      "        Sort non-concatenation axis if it is not already aligned when `join`\n",
      "        is 'outer'.\n",
      "        This has no effect when ``join='inner'``, which already preserves\n",
      "        the order of the non-concatenation axis.\n",
      "    \n",
      "        .. versionchanged:: 1.0.0\n",
      "    \n",
      "           Changed to not sort by default.\n",
      "    \n",
      "    copy : bool, default True\n",
      "        If False, do not copy data unnecessarily.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    object, type of objs\n",
      "        When concatenating all ``Series`` along the index (axis=0), a\n",
      "        ``Series`` is returned. When ``objs`` contains at least one\n",
      "        ``DataFrame``, a ``DataFrame`` is returned. When concatenating along\n",
      "        the columns (axis=1), a ``DataFrame`` is returned.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    DataFrame.join : Join DataFrames using indexes.\n",
      "    DataFrame.merge : Merge DataFrames by indexes or columns.\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    The keys, levels, and names arguments are all optional.\n",
      "    \n",
      "    A walkthrough of how this method fits in with other tools for combining\n",
      "    pandas objects can be found `here\n",
      "    <https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html>`__.\n",
      "    \n",
      "    It is not recommended to build DataFrames by adding single rows in a\n",
      "    for loop. Build a list of rows and make a DataFrame in a single concat.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    Combine two ``Series``.\n",
      "    \n",
      "    >>> s1 = pd.Series(['a', 'b'])\n",
      "    >>> s2 = pd.Series(['c', 'd'])\n",
      "    >>> pd.concat([s1, s2])\n",
      "    0    a\n",
      "    1    b\n",
      "    0    c\n",
      "    1    d\n",
      "    dtype: object\n",
      "    \n",
      "    Clear the existing index and reset it in the result\n",
      "    by setting the ``ignore_index`` option to ``True``.\n",
      "    \n",
      "    >>> pd.concat([s1, s2], ignore_index=True)\n",
      "    0    a\n",
      "    1    b\n",
      "    2    c\n",
      "    3    d\n",
      "    dtype: object\n",
      "    \n",
      "    Add a hierarchical index at the outermost level of\n",
      "    the data with the ``keys`` option.\n",
      "    \n",
      "    >>> pd.concat([s1, s2], keys=['s1', 's2'])\n",
      "    s1  0    a\n",
      "        1    b\n",
      "    s2  0    c\n",
      "        1    d\n",
      "    dtype: object\n",
      "    \n",
      "    Label the index keys you create with the ``names`` option.\n",
      "    \n",
      "    >>> pd.concat([s1, s2], keys=['s1', 's2'],\n",
      "    ...           names=['Series name', 'Row ID'])\n",
      "    Series name  Row ID\n",
      "    s1           0         a\n",
      "                 1         b\n",
      "    s2           0         c\n",
      "                 1         d\n",
      "    dtype: object\n",
      "    \n",
      "    Combine two ``DataFrame`` objects with identical columns.\n",
      "    \n",
      "    >>> df1 = pd.DataFrame([['a', 1], ['b', 2]],\n",
      "    ...                    columns=['letter', 'number'])\n",
      "    >>> df1\n",
      "      letter  number\n",
      "    0      a       1\n",
      "    1      b       2\n",
      "    >>> df2 = pd.DataFrame([['c', 3], ['d', 4]],\n",
      "    ...                    columns=['letter', 'number'])\n",
      "    >>> df2\n",
      "      letter  number\n",
      "    0      c       3\n",
      "    1      d       4\n",
      "    >>> pd.concat([df1, df2])\n",
      "      letter  number\n",
      "    0      a       1\n",
      "    1      b       2\n",
      "    0      c       3\n",
      "    1      d       4\n",
      "    \n",
      "    Combine ``DataFrame`` objects with overlapping columns\n",
      "    and return everything. Columns outside the intersection will\n",
      "    be filled with ``NaN`` values.\n",
      "    \n",
      "    >>> df3 = pd.DataFrame([['c', 3, 'cat'], ['d', 4, 'dog']],\n",
      "    ...                    columns=['letter', 'number', 'animal'])\n",
      "    >>> df3\n",
      "      letter  number animal\n",
      "    0      c       3    cat\n",
      "    1      d       4    dog\n",
      "    >>> pd.concat([df1, df3], sort=False)\n",
      "      letter  number animal\n",
      "    0      a       1    NaN\n",
      "    1      b       2    NaN\n",
      "    0      c       3    cat\n",
      "    1      d       4    dog\n",
      "    \n",
      "    Combine ``DataFrame`` objects with overlapping columns\n",
      "    and return only those that are shared by passing ``inner`` to\n",
      "    the ``join`` keyword argument.\n",
      "    \n",
      "    >>> pd.concat([df1, df3], join=\"inner\")\n",
      "      letter  number\n",
      "    0      a       1\n",
      "    1      b       2\n",
      "    0      c       3\n",
      "    1      d       4\n",
      "    \n",
      "    Combine ``DataFrame`` objects horizontally along the x axis by\n",
      "    passing in ``axis=1``.\n",
      "    \n",
      "    >>> df4 = pd.DataFrame([['bird', 'polly'], ['monkey', 'george']],\n",
      "    ...                    columns=['animal', 'name'])\n",
      "    >>> pd.concat([df1, df4], axis=1)\n",
      "      letter  number  animal    name\n",
      "    0      a       1    bird   polly\n",
      "    1      b       2  monkey  george\n",
      "    \n",
      "    Prevent the result from including duplicate index values with the\n",
      "    ``verify_integrity`` option.\n",
      "    \n",
      "    >>> df5 = pd.DataFrame([1], index=['a'])\n",
      "    >>> df5\n",
      "       0\n",
      "    a  1\n",
      "    >>> df6 = pd.DataFrame([2], index=['a'])\n",
      "    >>> df6\n",
      "       0\n",
      "    a  2\n",
      "    >>> pd.concat([df5, df6], verify_integrity=True)\n",
      "    Traceback (most recent call last):\n",
      "        ...\n",
      "    ValueError: Indexes have overlapping values: ['a']\n",
      "    \n",
      "    Append a single row to the end of a ``DataFrame`` object.\n",
      "    \n",
      "    >>> df7 = pd.DataFrame({'a': 1, 'b': 2}, index=[0])\n",
      "    >>> df7\n",
      "        a   b\n",
      "    0   1   2\n",
      "    >>> new_row = pd.Series({'a': 3, 'b': 4})\n",
      "    >>> new_row\n",
      "    a    3\n",
      "    b    4\n",
      "    dtype: int64\n",
      "    >>> pd.concat([df7, new_row.to_frame().T], ignore_index=True)\n",
      "        a   b\n",
      "    0   1   2\n",
      "    1   3   4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pd.concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21df756a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
