{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a53e823",
   "metadata": {},
   "outputs": [],
   "source": [
    "from investment_predictions import DataScraper, DataParser\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import time\n",
    "import openpyxl\n",
    "\n",
    "\n",
    "key_path = Path().home()/'desktop'/'FinancialModellingPrep_API.txt'\n",
    "with open(key_path) as file:\n",
    "    api_key = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf78b9cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "a = DataScraper('AAPL', api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "deacc624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# type(a.data_dictionary['price'])\n",
    "isinstance(a.data_dictionary['price'], pd.DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db4fb472",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas._libs.tslibs.timestamps.Timestamp"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pd.read_parquet(Path('investment_predictions')/'data'/\n",
    "                    'snp500_trading_data_1970_to_2023.parquet').index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35dea88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = DataParser(a.data_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad2fc491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1980-12-12 00:00:00-05:00</th>\n",
       "      <td>0.128348</td>\n",
       "      <td>0.128906</td>\n",
       "      <td>0.128348</td>\n",
       "      <td>0.128348</td>\n",
       "      <td>0.099722</td>\n",
       "      <td>469033600</td>\n",
       "      <td>1980-12-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-12-15 00:00:00-05:00</th>\n",
       "      <td>0.122210</td>\n",
       "      <td>0.122210</td>\n",
       "      <td>0.121652</td>\n",
       "      <td>0.121652</td>\n",
       "      <td>0.094519</td>\n",
       "      <td>175884800</td>\n",
       "      <td>1980-12-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-12-16 00:00:00-05:00</th>\n",
       "      <td>0.113281</td>\n",
       "      <td>0.113281</td>\n",
       "      <td>0.112723</td>\n",
       "      <td>0.112723</td>\n",
       "      <td>0.087582</td>\n",
       "      <td>105728000</td>\n",
       "      <td>1980-12-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-12-17 00:00:00-05:00</th>\n",
       "      <td>0.115513</td>\n",
       "      <td>0.116071</td>\n",
       "      <td>0.115513</td>\n",
       "      <td>0.115513</td>\n",
       "      <td>0.089749</td>\n",
       "      <td>86441600</td>\n",
       "      <td>1980-12-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-12-18 00:00:00-05:00</th>\n",
       "      <td>0.118862</td>\n",
       "      <td>0.119420</td>\n",
       "      <td>0.118862</td>\n",
       "      <td>0.118862</td>\n",
       "      <td>0.092351</td>\n",
       "      <td>73449600</td>\n",
       "      <td>1980-12-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-13 00:00:00-04:00</th>\n",
       "      <td>147.809998</td>\n",
       "      <td>153.139999</td>\n",
       "      <td>147.699997</td>\n",
       "      <td>150.470001</td>\n",
       "      <td>150.470001</td>\n",
       "      <td>84457100</td>\n",
       "      <td>2023-03-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-14 00:00:00-04:00</th>\n",
       "      <td>151.279999</td>\n",
       "      <td>153.399994</td>\n",
       "      <td>150.100006</td>\n",
       "      <td>152.589996</td>\n",
       "      <td>152.589996</td>\n",
       "      <td>73695900</td>\n",
       "      <td>2023-03-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-15 00:00:00-04:00</th>\n",
       "      <td>151.190002</td>\n",
       "      <td>153.250000</td>\n",
       "      <td>149.919998</td>\n",
       "      <td>152.990005</td>\n",
       "      <td>152.990005</td>\n",
       "      <td>77167900</td>\n",
       "      <td>2023-03-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-16 00:00:00-04:00</th>\n",
       "      <td>152.160004</td>\n",
       "      <td>156.460007</td>\n",
       "      <td>151.639999</td>\n",
       "      <td>155.850006</td>\n",
       "      <td>155.850006</td>\n",
       "      <td>76161100</td>\n",
       "      <td>2023-03-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-17 00:00:00-04:00</th>\n",
       "      <td>156.080002</td>\n",
       "      <td>156.740005</td>\n",
       "      <td>154.279999</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>98862500</td>\n",
       "      <td>2023-03-17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10655 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Open        High         Low       Close  \\\n",
       "Date                                                                        \n",
       "1980-12-12 00:00:00-05:00    0.128348    0.128906    0.128348    0.128348   \n",
       "1980-12-15 00:00:00-05:00    0.122210    0.122210    0.121652    0.121652   \n",
       "1980-12-16 00:00:00-05:00    0.113281    0.113281    0.112723    0.112723   \n",
       "1980-12-17 00:00:00-05:00    0.115513    0.116071    0.115513    0.115513   \n",
       "1980-12-18 00:00:00-05:00    0.118862    0.119420    0.118862    0.118862   \n",
       "...                               ...         ...         ...         ...   \n",
       "2023-03-13 00:00:00-04:00  147.809998  153.139999  147.699997  150.470001   \n",
       "2023-03-14 00:00:00-04:00  151.279999  153.399994  150.100006  152.589996   \n",
       "2023-03-15 00:00:00-04:00  151.190002  153.250000  149.919998  152.990005   \n",
       "2023-03-16 00:00:00-04:00  152.160004  156.460007  151.639999  155.850006   \n",
       "2023-03-17 00:00:00-04:00  156.080002  156.740005  154.279999  155.000000   \n",
       "\n",
       "                            Adj Close     Volume        date  \n",
       "Date                                                          \n",
       "1980-12-12 00:00:00-05:00    0.099722  469033600  1980-12-12  \n",
       "1980-12-15 00:00:00-05:00    0.094519  175884800  1980-12-15  \n",
       "1980-12-16 00:00:00-05:00    0.087582  105728000  1980-12-16  \n",
       "1980-12-17 00:00:00-05:00    0.089749   86441600  1980-12-17  \n",
       "1980-12-18 00:00:00-05:00    0.092351   73449600  1980-12-18  \n",
       "...                               ...        ...         ...  \n",
       "2023-03-13 00:00:00-04:00  150.470001   84457100  2023-03-13  \n",
       "2023-03-14 00:00:00-04:00  152.589996   73695900  2023-03-14  \n",
       "2023-03-15 00:00:00-04:00  152.990005   77167900  2023-03-15  \n",
       "2023-03-16 00:00:00-04:00  155.850006   76161100  2023-03-16  \n",
       "2023-03-17 00:00:00-04:00  155.000000   98862500  2023-03-17  \n",
       "\n",
       "[10655 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.data_dictionary['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cdab5af5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AAPL-Q1-2022    1.890000\n",
       "AAPL-Q4-2022    1.290000\n",
       "AAPL-Q3-2022    1.200000\n",
       "AAPL-Q2-2022    1.540000\n",
       "AAPL-Q1-2021    2.110000\n",
       "                  ...   \n",
       "AAPL-Q4-1986    0.000000\n",
       "AAPL-Q3-1986    0.002321\n",
       "AAPL-Q2-1986    0.002321\n",
       "AAPL-Q1-1985    0.004107\n",
       "AAPL-Q4-1985    0.000000\n",
       "Name: eps, Length: 150, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.is_.eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "768d72f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.is_.index.equals(b.ratios.index.equals(b.metrics.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "084028a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "diffs = []\n",
    "import datetime as dt\n",
    "for i, item in enumerate(b.metrics.date[1:]):\n",
    "    ly, lm, ld = [int(x) for x in b.ratios.date[i].split('-')]\n",
    "    last_date = dt.datetime(ly, lm, ld)\n",
    "    y, m, d = [int(x) for x in item.split('-')]\n",
    "    date_now = dt.datetime(y, m, d)\n",
    "    diffs.append(date_now-last_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9124f71d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-90),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-90),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-90),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-90),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-90),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-90),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-90),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-90),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-90),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-90),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-90),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-90),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-90),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-90),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-90),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-90),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-90),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-90),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-90),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-90),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-90),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-90),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-90),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-90),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-90),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-90),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-90),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-92),\n",
       " datetime.timedelta(days=-91),\n",
       " datetime.timedelta(days=-90),\n",
       " datetime.timedelta(days=-92)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22272446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function intersection in module pandas.core.indexes.base:\n",
      "\n",
      "intersection(self, other, sort=False)\n",
      "    Form the intersection of two Index objects.\n",
      "    \n",
      "    This returns a new Index with elements common to the index and `other`.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    other : Index or array-like\n",
      "    sort : False or None, default False\n",
      "        Whether to sort the resulting index.\n",
      "    \n",
      "        * False : do not sort the result.\n",
      "        * None : sort the result, except when `self` and `other` are equal\n",
      "          or when the values cannot be compared.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    intersection : Index\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> idx1 = pd.Index([1, 2, 3, 4])\n",
      "    >>> idx2 = pd.Index([3, 4, 5, 6])\n",
      "    >>> idx1.intersection(idx2)\n",
      "    Int64Index([3, 4], dtype='int64')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pd.Index.intersection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "496957cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas._libs.tslibs.timestamps.Timestamp"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(b.data_dictionary['price'][0].index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28e39a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas._libs.tslibs.timestamps import Timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "116e1dd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2020-10-01 00:00:00')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Timestamp(\"2020-10-01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ecb36f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function concat in module pandas.core.reshape.concat:\n",
      "\n",
      "concat(objs: 'Iterable[NDFrame] | Mapping[HashableT, NDFrame]', *, axis: 'Axis' = 0, join: 'str' = 'outer', ignore_index: 'bool' = False, keys=None, levels=None, names=None, verify_integrity: 'bool' = False, sort: 'bool' = False, copy: 'bool' = True) -> 'DataFrame | Series'\n",
      "    Concatenate pandas objects along a particular axis.\n",
      "    \n",
      "    Allows optional set logic along the other axes.\n",
      "    \n",
      "    Can also add a layer of hierarchical indexing on the concatenation axis,\n",
      "    which may be useful if the labels are the same (or overlapping) on\n",
      "    the passed axis number.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    objs : a sequence or mapping of Series or DataFrame objects\n",
      "        If a mapping is passed, the sorted keys will be used as the `keys`\n",
      "        argument, unless it is passed, in which case the values will be\n",
      "        selected (see below). Any None objects will be dropped silently unless\n",
      "        they are all None in which case a ValueError will be raised.\n",
      "    axis : {0/'index', 1/'columns'}, default 0\n",
      "        The axis to concatenate along.\n",
      "    join : {'inner', 'outer'}, default 'outer'\n",
      "        How to handle indexes on other axis (or axes).\n",
      "    ignore_index : bool, default False\n",
      "        If True, do not use the index values along the concatenation axis. The\n",
      "        resulting axis will be labeled 0, ..., n - 1. This is useful if you are\n",
      "        concatenating objects where the concatenation axis does not have\n",
      "        meaningful indexing information. Note the index values on the other\n",
      "        axes are still respected in the join.\n",
      "    keys : sequence, default None\n",
      "        If multiple levels passed, should contain tuples. Construct\n",
      "        hierarchical index using the passed keys as the outermost level.\n",
      "    levels : list of sequences, default None\n",
      "        Specific levels (unique values) to use for constructing a\n",
      "        MultiIndex. Otherwise they will be inferred from the keys.\n",
      "    names : list, default None\n",
      "        Names for the levels in the resulting hierarchical index.\n",
      "    verify_integrity : bool, default False\n",
      "        Check whether the new concatenated axis contains duplicates. This can\n",
      "        be very expensive relative to the actual data concatenation.\n",
      "    sort : bool, default False\n",
      "        Sort non-concatenation axis if it is not already aligned when `join`\n",
      "        is 'outer'.\n",
      "        This has no effect when ``join='inner'``, which already preserves\n",
      "        the order of the non-concatenation axis.\n",
      "    \n",
      "        .. versionchanged:: 1.0.0\n",
      "    \n",
      "           Changed to not sort by default.\n",
      "    \n",
      "    copy : bool, default True\n",
      "        If False, do not copy data unnecessarily.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    object, type of objs\n",
      "        When concatenating all ``Series`` along the index (axis=0), a\n",
      "        ``Series`` is returned. When ``objs`` contains at least one\n",
      "        ``DataFrame``, a ``DataFrame`` is returned. When concatenating along\n",
      "        the columns (axis=1), a ``DataFrame`` is returned.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    DataFrame.join : Join DataFrames using indexes.\n",
      "    DataFrame.merge : Merge DataFrames by indexes or columns.\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    The keys, levels, and names arguments are all optional.\n",
      "    \n",
      "    A walkthrough of how this method fits in with other tools for combining\n",
      "    pandas objects can be found `here\n",
      "    <https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html>`__.\n",
      "    \n",
      "    It is not recommended to build DataFrames by adding single rows in a\n",
      "    for loop. Build a list of rows and make a DataFrame in a single concat.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    Combine two ``Series``.\n",
      "    \n",
      "    >>> s1 = pd.Series(['a', 'b'])\n",
      "    >>> s2 = pd.Series(['c', 'd'])\n",
      "    >>> pd.concat([s1, s2])\n",
      "    0    a\n",
      "    1    b\n",
      "    0    c\n",
      "    1    d\n",
      "    dtype: object\n",
      "    \n",
      "    Clear the existing index and reset it in the result\n",
      "    by setting the ``ignore_index`` option to ``True``.\n",
      "    \n",
      "    >>> pd.concat([s1, s2], ignore_index=True)\n",
      "    0    a\n",
      "    1    b\n",
      "    2    c\n",
      "    3    d\n",
      "    dtype: object\n",
      "    \n",
      "    Add a hierarchical index at the outermost level of\n",
      "    the data with the ``keys`` option.\n",
      "    \n",
      "    >>> pd.concat([s1, s2], keys=['s1', 's2'])\n",
      "    s1  0    a\n",
      "        1    b\n",
      "    s2  0    c\n",
      "        1    d\n",
      "    dtype: object\n",
      "    \n",
      "    Label the index keys you create with the ``names`` option.\n",
      "    \n",
      "    >>> pd.concat([s1, s2], keys=['s1', 's2'],\n",
      "    ...           names=['Series name', 'Row ID'])\n",
      "    Series name  Row ID\n",
      "    s1           0         a\n",
      "                 1         b\n",
      "    s2           0         c\n",
      "                 1         d\n",
      "    dtype: object\n",
      "    \n",
      "    Combine two ``DataFrame`` objects with identical columns.\n",
      "    \n",
      "    >>> df1 = pd.DataFrame([['a', 1], ['b', 2]],\n",
      "    ...                    columns=['letter', 'number'])\n",
      "    >>> df1\n",
      "      letter  number\n",
      "    0      a       1\n",
      "    1      b       2\n",
      "    >>> df2 = pd.DataFrame([['c', 3], ['d', 4]],\n",
      "    ...                    columns=['letter', 'number'])\n",
      "    >>> df2\n",
      "      letter  number\n",
      "    0      c       3\n",
      "    1      d       4\n",
      "    >>> pd.concat([df1, df2])\n",
      "      letter  number\n",
      "    0      a       1\n",
      "    1      b       2\n",
      "    0      c       3\n",
      "    1      d       4\n",
      "    \n",
      "    Combine ``DataFrame`` objects with overlapping columns\n",
      "    and return everything. Columns outside the intersection will\n",
      "    be filled with ``NaN`` values.\n",
      "    \n",
      "    >>> df3 = pd.DataFrame([['c', 3, 'cat'], ['d', 4, 'dog']],\n",
      "    ...                    columns=['letter', 'number', 'animal'])\n",
      "    >>> df3\n",
      "      letter  number animal\n",
      "    0      c       3    cat\n",
      "    1      d       4    dog\n",
      "    >>> pd.concat([df1, df3], sort=False)\n",
      "      letter  number animal\n",
      "    0      a       1    NaN\n",
      "    1      b       2    NaN\n",
      "    0      c       3    cat\n",
      "    1      d       4    dog\n",
      "    \n",
      "    Combine ``DataFrame`` objects with overlapping columns\n",
      "    and return only those that are shared by passing ``inner`` to\n",
      "    the ``join`` keyword argument.\n",
      "    \n",
      "    >>> pd.concat([df1, df3], join=\"inner\")\n",
      "      letter  number\n",
      "    0      a       1\n",
      "    1      b       2\n",
      "    0      c       3\n",
      "    1      d       4\n",
      "    \n",
      "    Combine ``DataFrame`` objects horizontally along the x axis by\n",
      "    passing in ``axis=1``.\n",
      "    \n",
      "    >>> df4 = pd.DataFrame([['bird', 'polly'], ['monkey', 'george']],\n",
      "    ...                    columns=['animal', 'name'])\n",
      "    >>> pd.concat([df1, df4], axis=1)\n",
      "      letter  number  animal    name\n",
      "    0      a       1    bird   polly\n",
      "    1      b       2  monkey  george\n",
      "    \n",
      "    Prevent the result from including duplicate index values with the\n",
      "    ``verify_integrity`` option.\n",
      "    \n",
      "    >>> df5 = pd.DataFrame([1], index=['a'])\n",
      "    >>> df5\n",
      "       0\n",
      "    a  1\n",
      "    >>> df6 = pd.DataFrame([2], index=['a'])\n",
      "    >>> df6\n",
      "       0\n",
      "    a  2\n",
      "    >>> pd.concat([df5, df6], verify_integrity=True)\n",
      "    Traceback (most recent call last):\n",
      "        ...\n",
      "    ValueError: Indexes have overlapping values: ['a']\n",
      "    \n",
      "    Append a single row to the end of a ``DataFrame`` object.\n",
      "    \n",
      "    >>> df7 = pd.DataFrame({'a': 1, 'b': 2}, index=[0])\n",
      "    >>> df7\n",
      "        a   b\n",
      "    0   1   2\n",
      "    >>> new_row = pd.Series({'a': 3, 'b': 4})\n",
      "    >>> new_row\n",
      "    a    3\n",
      "    b    4\n",
      "    dtype: int64\n",
      "    >>> pd.concat([df7, new_row.to_frame().T], ignore_index=True)\n",
      "        a   b\n",
      "    0   1   2\n",
      "    1   3   4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pd.concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21df756a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
